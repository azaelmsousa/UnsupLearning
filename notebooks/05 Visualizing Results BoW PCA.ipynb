{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediods Analysis\n",
    "\n",
    "This experiment has the purpose of analysing the medoid of some of the clusters defined in the previous experiment. According to it, the best number of cluster is 82 regarding the square of the 2-norm distance, and 802 regarding the silhouette score. With 802 clusters, the silhouette score was 0.1, a considerably low value. Therefore, we won't consider it in the next experiments, implying that 82 is the best number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.15 wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(13229, 1203)\n"
     ]
    }
   ],
   "source": [
    "X = r.readBOW()\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.85, svd_solver='full')\n",
    "X = pca.fit_transform(X)\n",
    "npX = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "Read 13229 lines\n",
      "                   id                    publish_date  \\\n",
      "0  576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1  576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2  576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3  576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4  576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "5  576548368740052992  Sat Mar 14 01:00:17 +0000 2015   \n",
      "6  576518190286536704  Fri Mar 13 23:00:22 +0000 2015   \n",
      "7  576494177971732480  Fri Mar 13 21:24:57 +0000 2015   \n",
      "8  576472874946433024  Fri Mar 13 20:00:18 +0000 2015   \n",
      "9  576464606551490560  Fri Mar 13 19:27:27 +0000 2015   \n",
      "\n",
      "                                       headline_test  \n",
      "0  An abundance of online info can turn us into e...  \n",
      "1  A plant-based diet that incorporates fish may ...  \n",
      "2  It doesn't take much to damage your hearing at...  \n",
      "3  RT @CNN: Forever young? Discover this islandâ€™s...  \n",
      "4  RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "5  Maysoon Zayid, a touring standup comic with Ce...  \n",
      "6  How women can wipe out Alzheimer's, from @mari...  \n",
      "7  RT @CNNOpinion: Women can defeat #Alzheimers, ...  \n",
      "8         Is it time to raise the legal smoking age?  \n",
      "9  CDC: Misuse of garments may have led to releas...  \n",
      "(13229, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(r)\n",
    "news = r.readNews()\n",
    "print(news.head(10))\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Medoids\n",
    "In here, we compute the medoids as the closest point to the centroids of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 61\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 61\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 733)\n",
      "[[-0.02084702  0.00864816 -0.02207969 ... -0.00428908 -0.00508571\n",
      "   0.01500977]\n",
      " [ 0.13959183 -0.21770751 -0.11784142 ...  0.02807976  0.01087402\n",
      "   0.01806026]\n",
      " [ 0.33406802  0.02380238  0.12272257 ...  0.01926641  0.00619181\n",
      "   0.05321628]\n",
      " ...\n",
      " [-0.02140241 -0.01677267 -0.02584795 ...  0.04212087 -0.03687889\n",
      "  -0.03582874]\n",
      " [-0.01382887 -0.01317931 -0.02836163 ...  0.01689735  0.01340904\n",
      "  -0.00068102]\n",
      " [ 0.00650213  0.37024835 -0.12173441 ...  0.00950344  0.01638051\n",
      "  -0.0043304 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cluster_result.labels_\n",
    "arrays=[]\n",
    "for i in range(best_K):\n",
    "    dist = np.linalg.norm(best_cluster_result.cluster_centers_[i]-npX[y_pred==i],axis=1)\n",
    "    index = np.argmin(dist)\n",
    "    arrays.append(npX[y_pred==i][index])   \n",
    "\n",
    "medoids = np.vstack(arrays)\n",
    "print(medoids.shape)\n",
    "print(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7728 10512  9602  6330  6494   867  4205  9215  7082 10559  4317 12132\n",
      "  2785  9845   753  7202  2258  7884  6849  9915  3820 11004  9470  2212\n",
      "  6063 12418  4026   197  7125 12440  9558 11975 12493  5875 10380  2632\n",
      "  5053  1535  6089  4691  9963  5710  3289 12650 10151  6074 12642  2885\n",
      " 12601 12560 10440  4536  3189  6221  9302  1055 12778  1123  2806 12891\n",
      " 10182]\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(best_K):\n",
    "    l.append(np.where(np.all(npX==medoids[i],axis=1))[0][0]) # these last [0][0] return the index, since the output of this command is (array([id]),)\n",
    "    \n",
    "medoids_index = np.array(l)\n",
    "print(medoids_index)\n",
    "print(len(np.unique(medoids_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting medoids neighbors\n",
    "Here the medoids neighbors are selected in order to plot them and see if the clusters make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [38 51 28 14 42]\n",
      "Points: [[6089, 6233, 6295, 6345, 6395, 6444, 6500, 6665, 6731, 6798, 6946, 6998, 7049, 7106, 7247, 7309, 7437, 7546, 7596, 7647, 7702, 7753, 7808, 7949, 8014, 8064, 8115, 8179, 8312, 8372, 8436, 8485, 8534, 8583, 8639, 8874, 8937, 9000, 9071, 9158, 9208, 9270], [4536, 9997, 10415, 10419, 11328, 11331], [3060, 7125, 7138, 7638, 8515, 12108], [588, 753, 1397, 4131, 8450, 8698], [2894, 3289, 10197, 12185, 12477, 13214]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "nm = 5 #number of medoids to be analyzed\n",
    "nn = 5 #number of neighbor of each medoids\n",
    "np.random.seed(42)\n",
    "selected_medoids_index = np.random.randint(0,best_K,nm)\n",
    "selected_medoids = medoids[selected_medoids_index]\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "indexes_per_medoid = []\n",
    "\n",
    "for i in range(nm):\n",
    "    p = selected_medoids[i]\n",
    "    aux = npX[y_pred==selected_medoids_index[i]]\n",
    "    d = np.linalg.norm(aux-p,axis=1)\n",
    "    points = []\n",
    "    points.append(medoids_index[selected_medoids_index[i]])\n",
    "    \n",
    "    for j in range(nn):\n",
    "        min_d = d.argmin()\n",
    "        while (d[min_d] == 0.):\n",
    "            d[min_d] = np.inf\n",
    "            min_d = d.argmin()\n",
    "        points = points + (np.where(np.all(npX==aux[min_d],axis=1))[0]).tolist()\n",
    "        d[min_d] = np.inf\n",
    "        \n",
    "    indexes_per_medoid.append(np.unique(points).tolist())\n",
    "\n",
    "    \n",
    "print(\"Points:\",indexes_per_medoid)\n",
    "print(len(indexes_per_medoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Medoids\n",
    "Here we start the analysis of the medoids and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the news of the medoids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [38 51 28 14 42]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('../output/clusters_PCA/', exist_ok=True)\n",
    "os.makedirs('../output/medoids_PCA/', exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "for i in range(best_K):\n",
    "    np.savetxt(\"../output/clusters_PCA/k_\"+str(i)+\".txt\", news[y_pred==i].values, fmt='%s', encoding='utf8')\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    np.savetxt(\"../output/medoids_PCA/k_\"+str(selected_medoids_index[i])+\".txt\", np.take(news,p,0).values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News of the medoids and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "Everyday Health Daily Digest is out! \n",
      "\n",
      "----------------------------\n",
      "Record numbers sign up to Swiss right-to-die organization   \n",
      "\n",
      "Right-to-die campaigner Purdy dies \n",
      "\n",
      "VIDEO: US right-to-die advocate ends life \n",
      "\n",
      "US right-to-die advocate ends life \n",
      "\n",
      "VIDEO: Right-to-die judgement due \n",
      "\n",
      "Right-to-die court judgement due \n",
      "\n",
      "----------------------------\n",
      "Our obsession with sugar, salt and fat \n",
      "\n",
      "#Fibromyalgia: Kicking the Sugar Habit \n",
      "\n",
      "Which sugar substitute is best? This, and all your questions about sugar, answered! \n",
      "\n",
      "Are you addicted to sugar? 7 ways to control your sugar cravings: \n",
      "\n",
      "Divide grams of sugar by 4, and that's how many tsp of granulated sugar you're eating in every serving of any food! \n",
      "\n",
      "WHO: Sugar intake 'should be halved' \n",
      "\n",
      "----------------------------\n",
      "Train like a lady #lumberjack \n",
      "\n",
      "What's it like to have #schizophrenia? @andersoncooper took to a simulator to find out: \n",
      "\n",
      "Ha @DavidKirsch -- like this? \n",
      "\n",
      "Odd tune: Trumpeter's neck swells like a bullfrog \n",
      "\n",
      "This is what it feels like to be butt-naked \n",
      "\n",
      "Q4: Why do restaurants serve extremely large portions, like those in #XtremeEating? #HealthTalk \n",
      "\n",
      "----------------------------\n",
      "Understanding the rise in #ADHD diagnoses \n",
      "\n",
      "Unplanned pregnancies on rise in #military \n",
      "\n",
      "NI has largest HIV rise since 2000 \n",
      "\n",
      "NHS trusts with deficits rise to 39 \n",
      "\n",
      "The rise of the young non-drinkers \n",
      "\n",
      "Big rise in number of centenarians \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in indexes_per_medoid:\n",
    "    info = np.take(news,p,0).loc[:,\"headline_test\"].values\n",
    "    print(\"----------------------------\")\n",
    "    for i in range(info.size):\n",
    "        print(info[i],\"\\n\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating cloud of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs('../output/wordcloud_clusters_PCA/', exist_ok=True)\n",
    "os.makedirs('../output/wordcloud_medoids_PCA/', exist_ok=True)\n",
    "\n",
    "# clusters\n",
    "for i in range(best_K):\n",
    "    info = ' '.join(news[y_pred==i].loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_clusters_PCA/k_\"+str(i))\n",
    "    plt.close(fig)\n",
    "\n",
    "#medoids\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    info = ' '.join(np.take(news,p,0).loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_medoids_PCA/k_\"+str(selected_medoids_index[i]))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
