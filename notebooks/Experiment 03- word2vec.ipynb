{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the Clusters\n",
    "In this experiment, multiple metrics will be employed in order to validate the clusters. Metrics such as adjusted rand index, mutual information based scores, homogeneity, completeness and V-measure can not be used in this work because they require the ground truth (true labels) of the data.\n",
    "\n",
    "Number of clusters used: 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "[[ 0.02987077 -0.15110606 -0.02884087 ...  0.02446168 -0.08834651\n",
      "  -0.09221231]\n",
      " [ 0.05298314 -0.05420527  0.02592565 ...  0.01782615 -0.02950471\n",
      "   0.00508323]\n",
      " [ 0.07016749 -0.05757345 -0.13483836 ...  0.10909334 -0.0250241\n",
      "  -0.0654501 ]\n",
      " ...\n",
      " [ 0.11720041  0.02071754 -0.10931976 ... -0.05101222  0.00296909\n",
      "   0.03905441]\n",
      " [ 0.00200901 -0.04285163  0.09034279 ...  0.05065811 -0.01281281\n",
      "  -0.05488863]\n",
      " [ 0.0455922   0.00148772  0.06533482 ... -0.13578176 -0.0725346\n",
      "  -0.13827453]]\n",
      "[[ 0.02987077 -0.15110606 -0.02884087 ...  0.02446168 -0.08834651\n",
      "  -0.09221231]\n",
      " [ 0.05298314 -0.05420527  0.02592565 ...  0.01782615 -0.02950471\n",
      "   0.00508323]\n",
      " [ 0.07016749 -0.05757345 -0.13483836 ...  0.10909334 -0.0250241\n",
      "  -0.0654501 ]\n",
      " ...\n",
      " [ 0.10532002 -0.05241808 -0.02433    ... -0.01405231  0.03333547\n",
      "   0.01318201]\n",
      " [ 0.10429937 -0.1797766  -0.05073992 ...  0.01325834 -0.18105656\n",
      "  -0.07903843]\n",
      " [ 0.13153867 -0.05729359 -0.04480435 ... -0.00396843 -0.05132721\n",
      "   0.00955163]]\n",
      "(13229, 128)\n"
     ]
    }
   ],
   "source": [
    "X = r.readWord2Vec()\n",
    "npX = X\n",
    "print(npX)\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 32\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 32\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "y_pred = best_cluster_result.labels_\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there are any cluster with 0 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 274 elements\n",
      "Cluster 1 has 326 elements\n",
      "Cluster 2 has 153 elements\n",
      "Cluster 3 has 702 elements\n",
      "Cluster 4 has 426 elements\n",
      "Cluster 5 has 671 elements\n",
      "Cluster 6 has 468 elements\n",
      "Cluster 7 has 362 elements\n",
      "Cluster 8 has 491 elements\n",
      "Cluster 9 has 233 elements\n",
      "Cluster 10 has 278 elements\n",
      "Cluster 11 has 263 elements\n",
      "Cluster 12 has 306 elements\n",
      "Cluster 13 has 490 elements\n",
      "Cluster 14 has 329 elements\n",
      "Cluster 15 has 707 elements\n",
      "Cluster 16 has 382 elements\n",
      "Cluster 17 has 141 elements\n",
      "Cluster 18 has 650 elements\n",
      "Cluster 19 has 273 elements\n",
      "Cluster 20 has 312 elements\n",
      "Cluster 21 has 269 elements\n",
      "Cluster 22 has 506 elements\n",
      "Cluster 23 has 598 elements\n",
      "Cluster 24 has 417 elements\n",
      "Cluster 25 has 532 elements\n",
      "Cluster 26 has 566 elements\n",
      "Cluster 27 has 247 elements\n",
      "Cluster 28 has 610 elements\n",
      "Cluster 29 has 274 elements\n",
      "Cluster 30 has 645 elements\n",
      "Cluster 31 has 328 elements\n"
     ]
    }
   ],
   "source": [
    "for i in range(best_K):\n",
    "    print(\"Cluster \"+str(i)+\" has \"+str(npX[y_pred==i].shape[0])+\" elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies Bouldin\n",
    "This metric was not seen during classes but if the ground truth is not known, it can be used to evaluate the model. This index is defined as the average similarity between each cluster and its most similar one. Zero is the lowest possible score. Values closer to zero indicate a better partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies Bouldin\n",
      "4.694302904539041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    }
   ],
   "source": [
    "score_db = davies_bouldin_score(npX,y_pred)\n",
    "print(\"Davies Bouldin\")\n",
    "print(score_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback - Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13229,), (13229, 128))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calinski and Harabaz\n",
    "If the ground truth labels are not known, the Calinski-Harabaz index - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.\n",
    "To assess this metric, it must be computed for multiple clusters and visualy analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski and Harabaz\n",
      "80.4942113019822\n"
     ]
    }
   ],
   "source": [
    "score_ch = calinski_harabaz_score(npX,y_pred)\n",
    "print(\"Calinski and Harabaz\")\n",
    "print(score_ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
