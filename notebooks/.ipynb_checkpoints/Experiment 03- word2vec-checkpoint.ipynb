{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the Clusters\n",
    "In this experiment, multiple metrics will be employed in order to validate the clusters. Metrics such as adjusted rand index, mutual information based scores, homogeneity, completeness and V-measure can not be used in this work because they require the ground truth (true labels) of the data.\n",
    "\n",
    "Number of clusters used: 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "[[ 0.02987077 -0.15110606 -0.02884087 ...  0.02446168 -0.08834651\n",
      "  -0.09221231]\n",
      " [ 0.05298314 -0.05420527  0.02592565 ...  0.01782615 -0.02950471\n",
      "   0.00508323]\n",
      " [ 0.07016749 -0.05757345 -0.13483836 ...  0.10909334 -0.0250241\n",
      "  -0.0654501 ]\n",
      " ...\n",
      " [ 0.11720041  0.02071754 -0.10931976 ... -0.05101222  0.00296909\n",
      "   0.03905441]\n",
      " [ 0.00200901 -0.04285163  0.09034279 ...  0.05065811 -0.01281281\n",
      "  -0.05488863]\n",
      " [ 0.0455922   0.00148772  0.06533482 ... -0.13578176 -0.0725346\n",
      "  -0.13827453]]\n",
      "[[ 0.02987077 -0.15110606 -0.02884087 ...  0.02446168 -0.08834651\n",
      "  -0.09221231]\n",
      " [ 0.05298314 -0.05420527  0.02592565 ...  0.01782615 -0.02950471\n",
      "   0.00508323]\n",
      " [ 0.07016749 -0.05757345 -0.13483836 ...  0.10909334 -0.0250241\n",
      "  -0.0654501 ]\n",
      " ...\n",
      " [ 0.10532002 -0.05241808 -0.02433    ... -0.01405231  0.03333547\n",
      "   0.01318201]\n",
      " [ 0.10429937 -0.1797766  -0.05073992 ...  0.01325834 -0.18105656\n",
      "  -0.07903843]\n",
      " [ 0.13153867 -0.05729359 -0.04480435 ... -0.00396843 -0.05132721\n",
      "   0.00955163]]\n",
      "(13229, 128)\n"
     ]
    }
   ],
   "source": [
    "X = r.readWord2Vec()\n",
    "npX = X\n",
    "print(npX)\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 82\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 32\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "y_pred = best_cluster_result.labels_\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there are any cluster with 0 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has 24 elements\n",
      "Cluster 1 has 190 elements\n",
      "Cluster 2 has 175 elements\n",
      "Cluster 3 has 182 elements\n",
      "Cluster 4 has 170 elements\n",
      "Cluster 5 has 392 elements\n",
      "Cluster 6 has 51 elements\n",
      "Cluster 7 has 152 elements\n",
      "Cluster 8 has 275 elements\n",
      "Cluster 9 has 351 elements\n",
      "Cluster 10 has 118 elements\n",
      "Cluster 11 has 213 elements\n",
      "Cluster 12 has 94 elements\n",
      "Cluster 13 has 85 elements\n",
      "Cluster 14 has 90 elements\n",
      "Cluster 15 has 272 elements\n",
      "Cluster 16 has 244 elements\n",
      "Cluster 17 has 230 elements\n",
      "Cluster 18 has 247 elements\n",
      "Cluster 19 has 229 elements\n",
      "Cluster 20 has 135 elements\n",
      "Cluster 21 has 215 elements\n",
      "Cluster 22 has 154 elements\n",
      "Cluster 23 has 62 elements\n",
      "Cluster 24 has 16 elements\n",
      "Cluster 25 has 115 elements\n",
      "Cluster 26 has 344 elements\n",
      "Cluster 27 has 201 elements\n",
      "Cluster 28 has 151 elements\n",
      "Cluster 29 has 207 elements\n",
      "Cluster 30 has 180 elements\n",
      "Cluster 31 has 68 elements\n",
      "Cluster 32 has 306 elements\n",
      "Cluster 33 has 173 elements\n",
      "Cluster 34 has 151 elements\n",
      "Cluster 35 has 345 elements\n",
      "Cluster 36 has 42 elements\n",
      "Cluster 37 has 125 elements\n",
      "Cluster 38 has 222 elements\n",
      "Cluster 39 has 94 elements\n",
      "Cluster 40 has 21 elements\n",
      "Cluster 41 has 257 elements\n",
      "Cluster 42 has 99 elements\n",
      "Cluster 43 has 70 elements\n",
      "Cluster 44 has 168 elements\n",
      "Cluster 45 has 92 elements\n",
      "Cluster 46 has 44 elements\n",
      "Cluster 47 has 129 elements\n",
      "Cluster 48 has 113 elements\n",
      "Cluster 49 has 188 elements\n",
      "Cluster 50 has 105 elements\n",
      "Cluster 51 has 207 elements\n",
      "Cluster 52 has 124 elements\n",
      "Cluster 53 has 193 elements\n",
      "Cluster 54 has 209 elements\n",
      "Cluster 55 has 47 elements\n",
      "Cluster 56 has 95 elements\n",
      "Cluster 57 has 197 elements\n",
      "Cluster 58 has 95 elements\n",
      "Cluster 59 has 127 elements\n",
      "Cluster 60 has 25 elements\n",
      "Cluster 61 has 114 elements\n",
      "Cluster 62 has 95 elements\n",
      "Cluster 63 has 300 elements\n",
      "Cluster 64 has 333 elements\n",
      "Cluster 65 has 407 elements\n",
      "Cluster 66 has 185 elements\n",
      "Cluster 67 has 46 elements\n",
      "Cluster 68 has 175 elements\n",
      "Cluster 69 has 133 elements\n",
      "Cluster 70 has 77 elements\n",
      "Cluster 71 has 118 elements\n",
      "Cluster 72 has 294 elements\n",
      "Cluster 73 has 63 elements\n",
      "Cluster 74 has 226 elements\n",
      "Cluster 75 has 145 elements\n",
      "Cluster 76 has 92 elements\n",
      "Cluster 77 has 70 elements\n",
      "Cluster 78 has 78 elements\n",
      "Cluster 79 has 178 elements\n",
      "Cluster 80 has 265 elements\n",
      "Cluster 81 has 140 elements\n"
     ]
    }
   ],
   "source": [
    "for i in range(best_K):\n",
    "    print(\"Cluster \"+str(i)+\" has \"+str(npX[y_pred==i].shape[0])+\" elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies Bouldin\n",
    "This metric was not seen during classes but if the ground truth is not known, it can be used to evaluate the model. This index is defined as the average similarity between each cluster and its most similar one. Zero is the lowest possible score. Values closer to zero indicate a better partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies Bouldin\n",
      "4.1631135708591644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    }
   ],
   "source": [
    "score_db = davies_bouldin_score(npX,y_pred)\n",
    "print(\"Davies Bouldin\")\n",
    "print(score_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback - Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calinski and Harabaz\n",
    "If the ground truth labels are not known, the Calinski-Harabaz index - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabaz score relates to a model with better defined clusters.\n",
    "To assess this metric, it must be computed for multiple clusters and visualy analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski and Harabaz\n",
      "42.908535907090254\n"
     ]
    }
   ],
   "source": [
    "score_ch = calinski_harabaz_score(npX,y_pred)\n",
    "print(\"Calinski and Harabaz\")\n",
    "print(score_ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
