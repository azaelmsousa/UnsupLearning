{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediods Analysis\n",
    "\n",
    "This experiment has the purpose of analysing the medoid of some of the clusters defined in the previous experiment. According to it, the best number of cluster is 32 according with elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.15 wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "[[ 0.02987077 -0.15110606 -0.02884087 ...  0.02446168 -0.08834651\n",
      "  -0.09221231]\n",
      " [ 0.05298314 -0.05420527  0.02592565 ...  0.01782615 -0.02950471\n",
      "   0.00508323]\n",
      " [ 0.07016749 -0.05757345 -0.13483836 ...  0.10909334 -0.0250241\n",
      "  -0.0654501 ]\n",
      " ...\n",
      " [ 0.10532002 -0.05241808 -0.02433    ... -0.01405231  0.03333547\n",
      "   0.01318201]\n",
      " [ 0.10429937 -0.1797766  -0.05073992 ...  0.01325834 -0.18105656\n",
      "  -0.07903843]\n",
      " [ 0.13153867 -0.05729359 -0.04480435 ... -0.00396843 -0.05132721\n",
      "   0.00955163]]\n",
      "(13229, 128)\n"
     ]
    }
   ],
   "source": [
    "X = r.readWord2Vec()\n",
    "npX = X\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "Read 13229 lines\n",
      "                   id                    publish_date  \\\n",
      "0  576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1  576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2  576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3  576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4  576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "5  576548368740052992  Sat Mar 14 01:00:17 +0000 2015   \n",
      "6  576518190286536704  Fri Mar 13 23:00:22 +0000 2015   \n",
      "7  576494177971732480  Fri Mar 13 21:24:57 +0000 2015   \n",
      "8  576472874946433024  Fri Mar 13 20:00:18 +0000 2015   \n",
      "9  576464606551490560  Fri Mar 13 19:27:27 +0000 2015   \n",
      "\n",
      "                                       headline_test  \n",
      "0  An abundance of online info can turn us into e...  \n",
      "1  A plant-based diet that incorporates fish may ...  \n",
      "2  It doesn't take much to damage your hearing at...  \n",
      "3  RT @CNN: Forever young? Discover this islandâ€™s...  \n",
      "4  RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "5  Maysoon Zayid, a touring standup comic with Ce...  \n",
      "6  How women can wipe out Alzheimer's, from @mari...  \n",
      "7  RT @CNNOpinion: Women can defeat #Alzheimers, ...  \n",
      "8         Is it time to raise the legal smoking age?  \n",
      "9  CDC: Misuse of garments may have led to releas...  \n",
      "(13229, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(r)\n",
    "news = r.readNews()\n",
    "print(news.head(10))\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Medoids\n",
    "In here, we compute the medoids as the closest point to the centroids of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 32\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 32\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "[[ 0.12332614  0.01960983 -0.0883598  ...  0.08688914 -0.10242594\n",
      "  -0.01897467]\n",
      " [ 0.11083259 -0.10522303  0.03524468 ...  0.03864767  0.00544055\n",
      "  -0.06069441]\n",
      " [ 0.14511045 -0.1618841  -0.1077574  ...  0.0495424  -0.03909925\n",
      "  -0.12398614]\n",
      " ...\n",
      " [ 0.11508613 -0.1850927  -0.03711164 ...  0.05180415 -0.05892295\n",
      "  -0.05880312]\n",
      " [ 0.11582299 -0.09536775 -0.01162747 ...  0.03790362  0.01347604\n",
      "  -0.0544413 ]\n",
      " [ 0.16753181  0.03649224 -0.03392395 ...  0.01264674 -0.04756675\n",
      "  -0.05116208]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cluster_result.labels_\n",
    "arrays=[]\n",
    "for i in range(best_K):\n",
    "    dist = np.linalg.norm(best_cluster_result.cluster_centers_[i]-npX[y_pred==i],axis=1)\n",
    "    index = np.argmin(dist)\n",
    "    arrays.append(npX[y_pred==i][index])   \n",
    "\n",
    "medoids = np.vstack(arrays)\n",
    "print(medoids.shape)\n",
    "print(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12187  1049  7064  6889  8131  2381  3153  6046   610  7194  7631 10253\n",
      "   474  7898   493  8773  6089  7411  8672   741  7341  7725  2897  4309\n",
      "  1999  7987  7717  1115  1386  8664  1810  5716]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(best_K):\n",
    "    l.append(np.where(np.all(npX==medoids[i],axis=1))[0][0]) # these last [0][0] return the index, since the output of this command is (array([id]),)\n",
    "    \n",
    "medoids_index = np.array(l)\n",
    "print(medoids_index)\n",
    "print(len(np.unique(medoids_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting medoids neighbors\n",
    "Here the medoids neighbors are selected in order to plot them and see if the clusters make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [ 6 19 28 14 10]\n",
      "Points: [[567, 1135, 1714, 3153, 7038, 8434], [33, 576, 741, 895, 1075, 10909], [806, 1313, 1386, 3295, 7892, 8235], [493, 1730, 2173, 3385, 3506, 7944, 7977], [6564, 6846, 7608, 7631, 7931, 8346]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "nm = 5 #number of medoids to be analyzed\n",
    "nn = 5 #number of neighbor of each medoids\n",
    "np.random.seed(42)\n",
    "selected_medoids_index = np.random.randint(0,best_K,nm)\n",
    "selected_medoids = medoids[selected_medoids_index]\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "indexes_per_medoid = []\n",
    "\n",
    "for i in range(nm):\n",
    "    p = selected_medoids[i]\n",
    "    aux = npX[y_pred==selected_medoids_index[i]]\n",
    "    d = np.linalg.norm(aux-p,axis=1)\n",
    "    points = []\n",
    "    points.append(medoids_index[selected_medoids_index[i]])\n",
    "    \n",
    "    for j in range(nn):\n",
    "        min_d = d.argmin()\n",
    "        while (d[min_d] == 0.):\n",
    "            d[min_d] = np.inf\n",
    "            min_d = d.argmin()\n",
    "        points = points + (np.where(np.all(npX==aux[min_d],axis=1))[0]).tolist()\n",
    "        d[min_d] = np.inf\n",
    "        \n",
    "    indexes_per_medoid.append(np.unique(points).tolist())\n",
    "\n",
    "    \n",
    "print(\"Points:\",indexes_per_medoid)\n",
    "print(len(indexes_per_medoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Medoids\n",
    "Here we start the analysis of the medoids and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the news of the medoids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [ 6 19 28 14 10]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('../output/w2vec_clusters/', exist_ok=True)\n",
    "os.makedirs('../output/w2vec_medoids/', exist_ok=True)\n",
    "\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "for i in range(best_K):\n",
    "    np.savetxt(\"../output/w2vec_clusters/k_\"+str(i)+\".txt\", news[y_pred==i].values, fmt='%s', encoding='utf8')\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    np.savetxt(\"../output/w2vec_medoids/k_\"+str(selected_medoids_index[i])+\".txt\", np.take(news,p,0).values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News of the medoids and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "When you're sick, the last thing you want to do is get out of bed to see a doctor. These apps bring the doc to you! \n",
      "\n",
      "Do you have #autism or a loved one on the ASD spectrum? How do you communicate? Share your story w/ @cnnireport \n",
      "\n",
      "RT @PresJrCouncil: @deebeachgirl @cnnhealth Totally worth it! \"You are what you eat. What do you want to be?\" #betterinbalance \n",
      "\n",
      "RT @jdwilson2: Do you have a favorite T-shirt you just can't give up? Share a pic &amp; what it says about you using #TshirtTales \n",
      "\n",
      "If you want to tone up and lose weight you will love this fast-paced fat shedding workout: \n",
      "\n",
      "You just can't help but notice her awesome physique! Jennifer Aniston's diet and fitness secrets: \n",
      "\n",
      "----------------------------\n",
      "RT @CNNMoney: Tyson shares dropped after officials confirmed cases of bird flu in the U.S. \n",
      "\n",
      "#Ebola fears hit close to home: American Patrick Sawyer died in Nigeria after being infected by the deadly virus \n",
      "\n",
      "CDC worries mosquito-borne virus could hit U.S. after major outbreak in the Caribbean. \n",
      "\n",
      "Breaking:  First U.S. case of deadly #MERS virus reported in Indiana \n",
      "\n",
      "RT @DanielleCNN: Deadly #Ebola outbreak in Guinea continues. @WHO scales up response.  @DrSanjayGupta &amp; I decided to #GoThere. We leave tonâ€¦ \n",
      "\n",
      "Ebola crisis: Five top tips to avoid the deadly virus \n",
      "\n",
      "----------------------------\n",
      "Is your child getting enough sleep? @LivingWellDoc shares tips that will make for a happier baby in the a.m. \n",
      "\n",
      "You count calories, hit the gym and lose 1 lb. Your hubby drops 10 doing nothing. What's up with that??http://www.cnn.com/2014/02/20/health/upwave-weight-gender/index.html via @upwave \n",
      "\n",
      "RT @kellywallacetv: What's the advice when your child wants to stop a physical activity &amp; you know it's good for them to keep doing it? #fiâ€¦ \n",
      "\n",
      "Today's #getfit tip from @eatsmartbd: Don't eat with your wallet -- just b/c you paid for it doesn't mean you have to finish it! \n",
      "\n",
      "RT @Editaraelira: @EverydayHealth Keep myself &amp; everybody that I love always healthy as I've been doing for about three years :) #healthtalk \n",
      "\n",
      "RT @NPF: What works for one person with #psoriasis might not work for another. Keep trying until you find the right regimen for you #healthtalk \n",
      "\n",
      "----------------------------\n",
      "RT @R1NG0: Not sure what's harder, suffering with #depression or seeing someone you love suffer with it! Probably the latter! \n",
      "\n",
      "Do Catholic hospitals' directives prevent doctors from presenting patients with all the options? \n",
      "\n",
      "Nacho Arimany collaborates with @advancedbrain to compose music they say will benefit the brain. \n",
      "\n",
      "Today's #getfit tip from @TodayShow: Serious about losing weight? Put money on the line with @HealthyWage \n",
      "\n",
      "We were so impressed with your thoughts on treating #PTSD with ecstasy we decided to round 'em up and publish them \n",
      "\n",
      "Freshen the stale air in your home with these all-natural tips: \n",
      "\n",
      "Freshen the stale air in your home with these all-natural tips: \n",
      "\n",
      "----------------------------\n",
      "RT @eatsmartbd: A6 And don't focus only on the perimeter! Make the most of the middle of the #supermarket. #healthtalk @EverydayHealth \n",
      "\n",
      "RT @groovyplanteatr: Now I look forward to seasonal eating as well. Nothing better than fresh from the garden-yours or the farmers! #HealthTalk \n",
      "\n",
      "Grab the popcorn and dim the lights... here are the 10 greatest feel-good movies of all time! \n",
      "\n",
      "The lowdown on the FitBit, BodyMedia, and more body monitoring devices that are all the rage right now: \n",
      "\n",
      "Bored of brown rice? Try quinoa, and more of the trendiest foods of the year: \n",
      "\n",
      "Grab the popcorn and dim the lights... here are the 10 greatest feel-good movies of all time! \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in indexes_per_medoid:\n",
    "    info = np.take(news,p,0).loc[:,\"headline_test\"].values\n",
    "    print(\"----------------------------\")\n",
    "    for i in range(info.size):\n",
    "        print(info[i],\"\\n\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating cloud of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs('../output/w2vec_wordcloud_clusters/', exist_ok=True)\n",
    "os.makedirs('../output/w2vec_wordcloud_medoids/', exist_ok=True)\n",
    "\n",
    "# clusters\n",
    "for i in range(best_K):\n",
    "    info = ' '.join(news[y_pred==i].loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/w2vec_wordcloud_clusters/k_\"+str(i))\n",
    "    plt.close(fig)\n",
    "\n",
    "#medoids\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    info = ' '.join(np.take(news,p,0).loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/w2vec_wordcloud_medoids/k_\"+str(selected_medoids_index[i]))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
