{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediods Analysis\n",
    "\n",
    "This experiment has the purpose of analysing the medoid of some of the clusters defined in the previous experiment. According to it, the best number of cluster is 82 regarding the square of the 2-norm distance, and 802 regarding the silhouette score. With 802 clusters, the silhouette score was 0.1, a considerably low value. Therefore, we won't consider it in the next experiments, implying that 82 is the best number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.15 wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(13229, 1203)\n"
     ]
    }
   ],
   "source": [
    "X = r.readBOW()\n",
    "npX = X\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "Read 13229 lines\n",
      "                   id                    publish_date  \\\n",
      "0  576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1  576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2  576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3  576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4  576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "5  576548368740052992  Sat Mar 14 01:00:17 +0000 2015   \n",
      "6  576518190286536704  Fri Mar 13 23:00:22 +0000 2015   \n",
      "7  576494177971732480  Fri Mar 13 21:24:57 +0000 2015   \n",
      "8  576472874946433024  Fri Mar 13 20:00:18 +0000 2015   \n",
      "9  576464606551490560  Fri Mar 13 19:27:27 +0000 2015   \n",
      "\n",
      "                                       headline_test  \n",
      "0  An abundance of online info can turn us into e...  \n",
      "1  A plant-based diet that incorporates fish may ...  \n",
      "2  It doesn't take much to damage your hearing at...  \n",
      "3  RT @CNN: Forever young? Discover this islandâ€™s...  \n",
      "4  RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "5  Maysoon Zayid, a touring standup comic with Ce...  \n",
      "6  How women can wipe out Alzheimer's, from @mari...  \n",
      "7  RT @CNNOpinion: Women can defeat #Alzheimers, ...  \n",
      "8         Is it time to raise the legal smoking age?  \n",
      "9  CDC: Misuse of garments may have led to releas...  \n",
      "(13229, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(r)\n",
    "news = r.readNews()\n",
    "print(news.head(10))\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Medoids\n",
    "In here, we compute the medoids as the closest point to the centroids of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 82\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 82\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 1203)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.64301701 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cluster_result.labels_\n",
    "arrays=[]\n",
    "for i in range(best_K):\n",
    "    dist = np.linalg.norm(best_cluster_result.cluster_centers_[i]-npX[y_pred==i],axis=1)\n",
    "    index = np.argmin(dist)\n",
    "    arrays.append(npX[y_pred==i][index])   \n",
    "\n",
    "medoids = np.vstack(arrays)\n",
    "print(medoids.shape)\n",
    "print(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5922  4479 11837  1296  4340   890  4133  2313  1699  9356  5067  7141\n",
      "  7291  4614  7554  3872  3691  9420  2087  2568  5435  9313 10681  1723\n",
      "  3059  6829   313  2944  5753  2798 11178  5033   805 12468  3019 12783\n",
      "  3003    99  4218 11104  9819  3359  6082  6089 12965  6063 12162 10133\n",
      "  8891 10224  5853   779  2725  9473  6074  1532  6253  9451 10093  3697\n",
      "  2278   569  6132  3586  9670  3467  6318 10793  6501  2454  5020  2971\n",
      " 11436   891 10335  6977  9353  6401  7957  4876  3262  1743]\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(best_K):\n",
    "    l.append(np.where(np.all(npX==medoids[i],axis=1))[0][0]) # these last [0][0] return the index, since the output of this command is (array([id]),)\n",
    "    \n",
    "medoids_index = np.array(l)\n",
    "print(medoids_index)\n",
    "print(len(np.unique(medoids_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting medoids neighbors\n",
    "Here the medoids neighbors are selected in order to plot them and see if the clusters make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [51 14 71 60 20]\n",
      "Points: [[777, 779, 1175, 1177, 1185, 1186, 1187, 1692, 2375], [7208, 7506, 7513, 7516, 7554, 7612], [2971, 3592, 3943, 4107, 11598, 12568], [1940, 2278, 2300, 3759, 10173, 11783], [4288, 4966, 5435, 5606, 6980, 11492]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "nm = 5 #number of medoids to be analyzed\n",
    "nn = 5 #number of neighbor of each medoids\n",
    "np.random.seed(42)\n",
    "selected_medoids_index = np.random.randint(0,best_K,nm)\n",
    "selected_medoids = medoids[selected_medoids_index]\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "indexes_per_medoid = []\n",
    "\n",
    "for i in range(nm):\n",
    "    p = selected_medoids[i]\n",
    "    aux = npX[y_pred==selected_medoids_index[i]]\n",
    "    d = np.linalg.norm(aux-p,axis=1)\n",
    "    points = []\n",
    "    points.append(medoids_index[selected_medoids_index[i]])\n",
    "    \n",
    "    for j in range(nn):\n",
    "        min_d = d.argmin()\n",
    "        while (d[min_d] == 0.):\n",
    "            d[min_d] = np.inf\n",
    "            min_d = d.argmin()\n",
    "        points = points + (np.where(np.all(npX==aux[min_d],axis=1))[0]).tolist()\n",
    "        d[min_d] = np.inf\n",
    "        \n",
    "    indexes_per_medoid.append(np.unique(points).tolist())\n",
    "\n",
    "    \n",
    "print(\"Points:\",indexes_per_medoid)\n",
    "print(len(indexes_per_medoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Medoids\n",
    "Here we start the analysis of the medoids and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the news of the medoids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [51 14 71 60 20]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "for i in range(best_K):\n",
    "    np.savetxt(\"../output/clusters/k_\"+str(i)+\".txt\", news[y_pred==i].values, fmt='%s', encoding='utf8')\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    np.savetxt(\"../output/medoids/k_\"+str(selected_medoids_index[i])+\".txt\", np.take(news,p,0).values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News of the medoids and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "RT @DarianMurray: @cnnhealth oatmeal. Raisins, walnuts. \n",
      "\n",
      "We're chowing down on some mixed berry chia oatmeal. What's in your #breakfastbowl? Show us a pic for an RT! \n",
      "\n",
      "RT @UMN_Health: @cnnhealth @WilliamCNN We do, too! \n",
      "\n",
      "We practice what we preach! RT @WilliamCNN: #treadmilldesk @cnnhealth WOOT. \n",
      "\n",
      "Mmmm! RT @AtarheHoover: @cnnhealth \n",
      "\n",
      "RT @apelsinkaX: @cnnhealth \n",
      "\n",
      "RT @namibycandy: Quinoa flour pancakes topped w/ almond butter &amp; strawberries! ðŸ˜Š RT @cnnhealth What's in ur breakfast? Show us for RT! \n",
      "\n",
      "RT @cehfox: Agree completely: RT @Soledad_OBrien: \n",
      "\n",
      "RT @MayoClinic: RT @nhanson22 Memory loss: when to seek help: \n",
      "\n",
      "----------------------------\n",
      "Join us for a live chat at 12 pm ET in honor of #HeartMonth! @RachaelBegunRD will answer your heart-healthy living q's! Follow #HealthTalk \n",
      "\n",
      "RT @hollyejacobs: Excited to start @everydayhealth live chat for #WorldCancerDay in 1 MINUTE! Follow #HealthTalk to join the conversation. \n",
      "\n",
      "ONE HOUR til our chat w/ @hollyejacobs for #WorldCancerDay! Bring your q's and follow #HealthTalk to join the convo! \n",
      "\n",
      "Join us at 12 pm ET today for a #HealthTalk w/ @hollyejacobs for #WorldCancerDay! Follow #HealthTalk to participate \n",
      "\n",
      "Join us for a live chat w/ @hollyejacobs for #WorldCancerDay on Mon @ 12 pm ET. Follow #HealthTalk to join the convo! \n",
      "\n",
      "Monday is #WorldCancerDay! @hollyejacobs joins us for a chat @ 12 pm ET \n",
      "\n",
      "----------------------------\n",
      "In sickness and in health: A tale of two counties \n",
      "\n",
      "#Health Minute: Meditation may improve heart health \n",
      "\n",
      "#Health minute: Fish oils and heart health \n",
      "\n",
      "5 ways your commute is hurting your health   \n",
      "\n",
      "Health MoTs for psychiatric patients \n",
      "\n",
      "'Health risk' church bells silenced \n",
      "\n",
      "----------------------------\n",
      "Are you faking it? (Ahemâ€¦your health food that is!) \n",
      "\n",
      "How supersized food hijacked the Earth \n",
      "\n",
      "This is your brain on food \n",
      "\n",
      "How to shop for #healthy food \n",
      "\n",
      "VIDEO: 'I was terrified to be around food' \n",
      "\n",
      "'A third' can't afford healthy food \n",
      "\n",
      "----------------------------\n",
      "Merck says melanoma drug meets goal; study halted  \n",
      "\n",
      "#Lesbians may be at heightened risk of cervical #cancer, study says \n",
      "\n",
      "Replacement for BPA in plastics also suspect, study says \n",
      "\n",
      "Study says 2 cups of milk may be ideal for preschoolers \n",
      "\n",
      "It's not what you eat, but how much, that matters, a new study says: \n",
      "\n",
      "Bug repellent 'is safe', study says \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in indexes_per_medoid:\n",
    "    info = np.take(news,p,0).loc[:,\"headline_test\"].values\n",
    "    print(\"----------------------------\")\n",
    "    for i in range(info.size):\n",
    "        print(info[i],\"\\n\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating cloud of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# clusters\n",
    "for i in range(best_K):\n",
    "    info = ' '.join(news[y_pred==i].loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_clusters/k_\"+str(i))\n",
    "    plt.close(fig)\n",
    "\n",
    "#medoids\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    info = ' '.join(np.take(news,p,0).loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_medoids/k_\"+str(selected_medoids_index[i]))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
