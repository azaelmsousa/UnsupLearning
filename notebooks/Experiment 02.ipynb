{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediods Analysis\n",
    "\n",
    "This experiment has the purpose of analysing the medoid of some of the clusters defined in the previous experiment. According to it, the best number of cluster is 72 regarding the square of the 2-norm distance, and 802 regarding the silhouette score. With 802 clusters, the silhouette score was 0.1, a considerably low value. Therefore, we won't consider it in the next experiments, implying that 72 is the best number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health.txt', 'bags.csv', 'word2vec.csv']\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "   0     1     2     3     4     5     6     7     8     9     ...   1193  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
      "\n",
      "   1194  1195  1196  1197  1198  1199      1200  1201  1202  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0  0.552201   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
      "\n",
      "[10 rows x 1203 columns]\n",
      "(13229, 1203)\n"
     ]
    }
   ],
   "source": [
    "X = r.readBOW()\n",
    "npX = X.values\n",
    "print(npX)\n",
    "print(X.head(10))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health.txt', 'bags.csv', 'word2vec.csv']\n",
      "                   id                    publish_date  \\\n",
      "0  576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1  576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2  576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3  576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4  576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "5  576548368740052992  Sat Mar 14 01:00:17 +0000 2015   \n",
      "6  576518190286536704  Fri Mar 13 23:00:22 +0000 2015   \n",
      "7  576494177971732480  Fri Mar 13 21:24:57 +0000 2015   \n",
      "8  576472874946433024  Fri Mar 13 20:00:18 +0000 2015   \n",
      "9  576464606551490560  Fri Mar 13 19:27:27 +0000 2015   \n",
      "\n",
      "                                       headline_test  \n",
      "0  An abundance of online info can turn us into e...  \n",
      "1  A plant-based diet that incorporates fish may ...  \n",
      "2  It doesn't take much to damage your hearing at...  \n",
      "3  RT @CNN: Forever young? Discover this island’s...  \n",
      "4  RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "5  Maysoon Zayid, a touring standup comic with Ce...  \n",
      "6  How women can wipe out Alzheimer's, from @mari...  \n",
      "7  RT @CNNOpinion: Women can defeat #Alzheimers, ...  \n",
      "8         Is it time to raise the legal smoking age?  \n",
      "9  CDC: Misuse of garments may have led to releas...  \n",
      "(13229, 3)\n"
     ]
    }
   ],
   "source": [
    "news = r.readNews()\n",
    "print(news.head(10))\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Medoids\n",
    "In here, we compute the medoids as the closest point to the centroids of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 72\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 72\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1203)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cluster_result.labels_\n",
    "arrays=[]\n",
    "for i in range(best_K):\n",
    "    dist = np.linalg.norm(best_cluster_result.cluster_centers_[i]-npX[y_pred==i],axis=1)\n",
    "    index = np.argmin(dist)\n",
    "    arrays.append(npX[y_pred==i][index])   \n",
    "\n",
    "medoids = np.vstack(arrays)\n",
    "print(medoids.shape)\n",
    "print(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   99  2278  3257  3691  9451  9313  4181   777  2299  3697   569  7291\n",
      "  9420  5444 12108  6089  5940   851 10224  3043  5875   817  2938  5067\n",
      "   315  2751  7576  4566  4387  2798  2529  8891  5033 11025  2464  1546\n",
      "  2944  3725  9979  4131  6852  4107  6063  2971  6390  9599  4130 11178\n",
      "  3003   616   401  1168 10247   188  7991   962  5812  4897 12881  4016\n",
      "   681   841  5091  2206  5435  3490 10133  1723  4614  4287  1298  2889]\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(best_K):\n",
    "    l.append(np.where(np.all(npX==medoids[i],axis=1))[0][0]) # these last [0][0] return the index, since the output of this command is (array([id]),)\n",
    "    \n",
    "medoids_index = np.array(l)\n",
    "print(medoids_index)\n",
    "print(len(np.unique(medoids_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting medoids neighbors\n",
    "Here the medoids neighbors are selected in order to plot them and see if the clusters make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [38 51 28 14 42]\n",
      "Points: [[9979, 10500, 10644, 10657, 10983, 12162], [734, 1168, 6787, 7699, 8094, 9746], [4387, 5871, 9304, 11738, 12027, 12129], [4401, 7138, 7638, 8515, 11321, 12108], [4668, 6063, 6664, 6763, 9070, 9178]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "nm = 5 #number of medoids to be analyzed\n",
    "nn = 5 #number of neighbor of each medoids\n",
    "np.random.seed(42)\n",
    "selected_medoids_index = np.random.randint(0,61,nm)\n",
    "selected_medoids = medoids[selected_medoids_index]\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "indexes_per_medoid = []\n",
    "\n",
    "for i in range(nm):\n",
    "    p = selected_medoids[i]\n",
    "    aux = npX[y_pred==selected_medoids_index[i]]\n",
    "    d = np.linalg.norm(aux-p,axis=1)\n",
    "    points = []\n",
    "    points.append(medoids_index[selected_medoids_index[i]])\n",
    "    \n",
    "    for j in range(nn):\n",
    "        min_d = d.argmin()\n",
    "        while (d[min_d] == 0.):\n",
    "            d[min_d] = np.inf\n",
    "            min_d = d.argmin()\n",
    "        points = points + (np.where(np.all(npX==aux[min_d],axis=1))[0]).tolist()\n",
    "        d[min_d] = np.inf\n",
    "        \n",
    "    indexes_per_medoid.append(np.unique(points).tolist())\n",
    "\n",
    "    \n",
    "print(\"Points:\",indexes_per_medoid)\n",
    "print(len(indexes_per_medoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Medoids\n",
    "Here we start the analysis of the medoids and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the news of the medoids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [38 51 28 14 42]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "for i in range(best_K):\n",
    "    np.savetxt(\"../output/clusters/k_\"+str(i)+\".txt\", news[y_pred==i].values, fmt='%s')\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    np.savetxt(\"../output/medoids/k_\"+str(selected_medoids_index[i])+\".txt\", np.take(news,p,0).values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News of the medoids and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Ebola flights' UK passengers traced \n",
      "\n",
      "VIDEO: UK Ebola planning 'excellent' \n",
      "\n",
      "VIDEO: Ebola: UK 'must not be complacent' \n",
      "\n",
      "VIDEO: Ebola: 'Stringent procedures' in UK \n",
      "\n",
      "VIDEO: How the UK is guarding against Ebola \n",
      "\n",
      "The spinal pains of the UK workforce \n",
      "\n",
      "----------------------------\n",
      "RT @jdwilson2: LOVE this new take on our #WeeklyWeighIn series -- She gained weight to love her body \n",
      "\n",
      "@PublicHealth We'd love to! \n",
      "\n",
      "Give love, get love and love your heart #valentinesday \n",
      "\n",
      "How to help someone you love #quitsmoking \n",
      "\n",
      "Why you fell in love with your shnookums, or whatever you like to call you call your significant other! \n",
      "\n",
      "How much do we love the NHS? \n",
      "\n",
      "----------------------------\n",
      "Doctors’ unconscious bias may not influence their decisions  \n",
      "\n",
      "Doctors dole out prescriptions for #exercise \n",
      "\n",
      "Coalition 'undermined NHS' - doctors \n",
      "\n",
      "Mad-doctors and inconvenient people \n",
      "\n",
      "The A&amp;E doctors moving to Australia \n",
      "\n",
      "Doctors aim to grow ears from fat \n",
      "\n",
      "----------------------------\n",
      "The 4 most confusing things about sugar   \n",
      "\n",
      "Which sugar substitute is best? This, and all your questions about sugar, answered! \n",
      "\n",
      "Are you addicted to sugar? 7 ways to control your sugar cravings: \n",
      "\n",
      "Divide grams of sugar by 4, and that's how many tsp of granulated sugar you're eating in every serving of any food! \n",
      "\n",
      "How much sugar do we eat? \n",
      "\n",
      "WHO: Sugar intake 'should be halved' \n",
      "\n",
      "----------------------------\n",
      "Warming up can slim you down \n",
      "\n",
      "10 foods that boost your skin AND slim your waistline: \n",
      "\n",
      "10 foods that boost your skin &amp; slim your waistline: \n",
      "\n",
      "10 foods that will boost your overall health, plus make your skin glow: \n",
      "\n",
      "10 foods that boost your skin &amp; slim your waistline: \n",
      "\n",
      "10 foods that will boost your overall health, plus make your skin glow: \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in indexes_per_medoid:\n",
    "    info = np.take(news,p,0).loc[:,\"headline_test\"].values\n",
    "    print(\"----------------------------\")\n",
    "    for i in range(info.size):\n",
    "        print(info[i],\"\\n\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating cloud of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# clusters\n",
    "for i in range(best_K):\n",
    "    info = ' '.join(news[y_pred==i].loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_clusters/k_\"+str(i))\n",
    "    plt.close(fig)\n",
    "\n",
    "#medoids\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    info = ' '.join(np.take(news,p,0).loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/wordcloud_medoids/k_\"+str(selected_medoids_index[i]))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
