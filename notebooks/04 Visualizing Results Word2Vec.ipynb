{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediods Analysis\n",
    "\n",
    "This experiment has the purpose of analysing the medoid of some of the clusters defined in the previous experiment. According to it, the best number of cluster is 32 according with elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.15 wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from src import reader as r\n",
    "from src import visualization as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.013595 -0.068772 -0.013126  0.006024  0.037922 -0.020872 -0.010325   \n",
      "1  0.025009 -0.025586  0.012237  0.020567  0.014523 -0.018705 -0.058395   \n",
      "2  0.031544 -0.025882 -0.060617  0.035992  0.037742 -0.021132 -0.041023   \n",
      "3  0.058714 -0.080251 -0.026101  0.060461  0.016714 -0.005205 -0.037441   \n",
      "4  0.023366 -0.065667 -0.015601  0.022602  0.030365 -0.060590 -0.071055   \n",
      "5  0.005894 -0.074649 -0.001171  0.014182  0.029530  0.025231 -0.022154   \n",
      "6 -0.011415 -0.021273 -0.043368 -0.001785 -0.031960 -0.020326 -0.071195   \n",
      "7  0.049307 -0.024540 -0.011390  0.010187  0.017417 -0.000969 -0.020045   \n",
      "8  0.052583 -0.090634 -0.025581  0.003195  0.031459  0.002013  0.025611   \n",
      "9  0.061589 -0.026826 -0.020978  0.046825  0.002022 -0.016367 -0.058929   \n",
      "\n",
      "        7         8         9      ...          118       119       120  \\\n",
      "0  0.008019  0.008064  0.011381    ...    -0.020965  0.062473 -0.000060   \n",
      "1  0.028054 -0.032362  0.020582    ...    -0.034977  0.030475  0.038899   \n",
      "2  0.011076  0.003247  0.014427    ...    -0.000146  0.000293  0.029334   \n",
      "3  0.051472 -0.063505  0.003247    ...    -0.021879  0.017103  0.016472   \n",
      "4 -0.008641 -0.018728  0.042880    ...     0.014219  0.051613  0.027316   \n",
      "5  0.045819 -0.011713  0.047938    ...    -0.018329  0.043745 -0.060474   \n",
      "6  0.052319  0.024060  0.011016    ...    -0.003169  0.044308 -0.023204   \n",
      "7  0.026669  0.008933 -0.032209    ...    -0.039200  0.047800 -0.010576   \n",
      "8  0.035871  0.014359  0.047947    ...     0.032896  0.029130 -0.010469   \n",
      "9  0.057065 -0.034253  0.015480    ...    -0.030948  0.032338  0.002056   \n",
      "\n",
      "        121       122       123       124       125       126       127  \n",
      "0 -0.062621 -0.019586  0.046007  0.003811  0.011133 -0.040208 -0.041968  \n",
      "1  0.016926 -0.000666  0.007311  0.001348  0.008414 -0.013927  0.002399  \n",
      "2 -0.005735 -0.025683  0.028694  0.028692  0.049043 -0.011250 -0.029423  \n",
      "3 -0.004953 -0.001521 -0.018822  0.020216  0.025708 -0.016543  0.012973  \n",
      "4 -0.030006 -0.028209  0.064256 -0.019291  0.003725 -0.049937 -0.015975  \n",
      "5 -0.007864 -0.010597  0.095285  0.068036  0.004613 -0.016592 -0.016851  \n",
      "6 -0.105190 -0.045768  0.056052  0.010088 -0.017446 -0.036269  0.007241  \n",
      "7 -0.020911 -0.021944  0.052267  0.042141 -0.006579  0.015606  0.006171  \n",
      "8 -0.059175  0.001889  0.010496  0.017496  0.006684 -0.091280 -0.039847  \n",
      "9  0.014193 -0.025909  0.046399  0.025248 -0.001858 -0.024032  0.004472  \n",
      "\n",
      "[10 rows x 128 columns]\n",
      "(13229, 128)\n"
     ]
    }
   ],
   "source": [
    "X = r.readWord2Vec(normed=False)\n",
    "npX = X.values\n",
    "print(X[:10])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word2vec.csv', 'bags.csv', 'health.txt', 'health-dataset.zip', 'health-dataset']\n",
      "Read 13229 lines\n",
      "                   id                    publish_date  \\\n",
      "0  576880531301801984  Sat Mar 14 23:00:11 +0000 2015   \n",
      "1  576820122666471424  Sat Mar 14 19:00:08 +0000 2015   \n",
      "2  576744652717461504  Sat Mar 14 14:00:15 +0000 2015   \n",
      "3  576736754436304896  Sat Mar 14 13:28:52 +0000 2015   \n",
      "4  576736614766010368  Sat Mar 14 13:28:18 +0000 2015   \n",
      "5  576548368740052992  Sat Mar 14 01:00:17 +0000 2015   \n",
      "6  576518190286536704  Fri Mar 13 23:00:22 +0000 2015   \n",
      "7  576494177971732480  Fri Mar 13 21:24:57 +0000 2015   \n",
      "8  576472874946433024  Fri Mar 13 20:00:18 +0000 2015   \n",
      "9  576464606551490560  Fri Mar 13 19:27:27 +0000 2015   \n",
      "\n",
      "                                       headline_test  \n",
      "0  An abundance of online info can turn us into e...  \n",
      "1  A plant-based diet that incorporates fish may ...  \n",
      "2  It doesn't take much to damage your hearing at...  \n",
      "3  RT @CNN: Forever young? Discover this islandâ€™s...  \n",
      "4  RT @CNN: Is post-traumatic stress disorder in ...  \n",
      "5  Maysoon Zayid, a touring standup comic with Ce...  \n",
      "6  How women can wipe out Alzheimer's, from @mari...  \n",
      "7  RT @CNNOpinion: Women can defeat #Alzheimers, ...  \n",
      "8         Is it time to raise the legal smoking age?  \n",
      "9  CDC: Misuse of garments may have led to releas...  \n",
      "(13229, 3)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(r)\n",
    "news = r.readNews()\n",
    "print(news.head(10))\n",
    "print(news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "smp_sz = X.size\n",
    "tsne_bow = TSNE(n_components=2, perplexity=10, verbose=True, n_jobs=-1)#500\n",
    "tsne_bow_result = tsne_bow.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Medoids\n",
    "In here, we compute the medoids as the closest point to the centroids of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Best K = 22\n",
      "Applying K-means\n",
      "Finished\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "best_K = 22\n",
    "print(\"#############################\")\n",
    "print(\"Best K =\", best_K)\n",
    "print(\"Applying K-means\")\n",
    "best_cluster = KMeans(n_clusters=best_K, n_jobs=-1)\n",
    "best_cluster_result = best_cluster.fit(X)\n",
    "print(\"Finished\")\n",
    "print(\"#############################\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 128)\n",
      "[[ 0.03621743 -0.02559954  0.0001907  ...  0.009918   -0.026162\n",
      "  -0.04250124]\n",
      " [ 0.02881752 -0.00065937 -0.02970518 ...  0.03434596 -0.04455674\n",
      "  -0.02181085]\n",
      " [ 0.04371578 -0.00270727 -0.01084024 ...  0.02332169 -0.03504989\n",
      "  -0.00562588]\n",
      " ...\n",
      " [ 0.05481039 -0.04737444  0.0006567  ...  0.05074434  0.01596553\n",
      "  -0.03167734]\n",
      " [ 0.0326329  -0.0393059   0.03538762 ...  0.01153963 -0.05382344\n",
      "   0.02522494]\n",
      " [ 0.05162259 -0.09289704  0.01216706 ...  0.04618941 -0.01589652\n",
      "  -0.04103516]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_cluster_result.labels_\n",
    "arrays=[]\n",
    "for i in range(best_K):\n",
    "    dist = np.linalg.norm(best_cluster_result.cluster_centers_[i]-npX[y_pred==i],axis=1)\n",
    "    index = np.argmin(dist)\n",
    "    arrays.append(npX[y_pred==i][index])   \n",
    "\n",
    "medoids = np.vstack(arrays)\n",
    "print(medoids.shape)\n",
    "print(medoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9292 10105  2040  1810  7972  1672  1999  6268   567  7194  3079  7725\n",
      "   414  8131  1469  1115  6536  7898   554  3626  7717  6889]\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(best_K):\n",
    "    l.append(np.where(np.all(npX==medoids[i],axis=1))[0][0]) # these last [0][0] return the index, since the output of this command is (array([id]),)\n",
    "    \n",
    "medoids_index = np.array(l)\n",
    "print(medoids_index)\n",
    "print(len(np.unique(medoids_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting medoids neighbors\n",
    "Here the medoids neighbors are selected in order to plot them and see if the clusters make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [ 6 19 14 10  7]\n",
      "Points: [[322, 1999, 2096, 2599, 5801, 10501], [1380, 1666, 1837, 3626, 7341, 8235], [1468, 1469, 3400, 9658, 9753, 10465], [1571, 2120, 3079, 3177, 4796, 7987], [303, 1333, 5454, 5566, 6268, 8841]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "nm = 5 #number of medoids to be analyzed\n",
    "nn = 5 #number of neighbor of each medoids\n",
    "np.random.seed(42)\n",
    "selected_medoids_index = np.random.randint(0,best_K,nm)\n",
    "selected_medoids = medoids[selected_medoids_index]\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "indexes_per_medoid = []\n",
    "\n",
    "for i in range(nm):\n",
    "    p = selected_medoids[i]\n",
    "    aux = npX[y_pred==selected_medoids_index[i]]\n",
    "    d = np.linalg.norm(aux-p,axis=1)\n",
    "    points = []\n",
    "    points.append(medoids_index[selected_medoids_index[i]])\n",
    "    \n",
    "    for j in range(nn):\n",
    "        min_d = d.argmin()\n",
    "        while (d[min_d] == 0.):\n",
    "            d[min_d] = np.inf\n",
    "            min_d = d.argmin()\n",
    "        points = points + (np.where(np.all(npX==aux[min_d],axis=1))[0]).tolist()\n",
    "        d[min_d] = np.inf\n",
    "        \n",
    "    indexes_per_medoid.append(np.unique(points).tolist())\n",
    "\n",
    "    \n",
    "print(\"Points:\",indexes_per_medoid)\n",
    "print(len(indexes_per_medoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Medoids\n",
    "Here we start the analysis of the medoids and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the news of the medoids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indexes: [ 6 19 14 10  7]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('../output/w2vec_clusters/', exist_ok=True)\n",
    "os.makedirs('../output/w2vec_medoids/', exist_ok=True)\n",
    "\n",
    "print(\"Random indexes:\",selected_medoids_index)\n",
    "for i in range(best_K):\n",
    "    np.savetxt(\"../output/w2vec_clusters/k_\"+str(i)+\".txt\", news[y_pred==i].values, fmt='%s', encoding='utf8')\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    np.savetxt(\"../output/w2vec_medoids/k_\"+str(selected_medoids_index[i])+\".txt\", np.take(news,p,0).values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News of the medoids and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "American #Ebola patient Dr. Rick Sacra has been released from the hospital \n",
      "\n",
      "Health Hero of the Day! Hospital staff sews up kid's favorite stuffed animal during surgery \n",
      "\n",
      "Kentucky hospital settles lawsuit over pediatric program \n",
      "\n",
      "Who knew? Copper in hospital rooms may stop infections \n",
      "\n",
      "In mysterious case, hospital sees second death from cyanide poisoning \n",
      "\n",
      "VIDEO: PM challenged on girl's hospital letter \n",
      "\n",
      "----------------------------\n",
      "RT @denisermt: @cnnhealth A4) For free time playtime, we visit the park, playground or the beach for unstructured, let kids be kids playtimâ€¦ \n",
      "\n",
      "RT @NAMICommunicate: @EAVrotsos Funding for #mentalhealth varies by state, yes. For the latest snapshot on $ in states, \n",
      "\n",
      "Testosterone replacement is the hot new therapy for men. But \"T\" could be dangerous for your hubby's heart \n",
      "\n",
      "RT @UNAIDS reports a gap of US$7.2 bn in 2011 to reach the global #HIV targets for low &amp; middle income countries for 2015 \n",
      "\n",
      "RT @EinsteinMed: A7: It has been used for over 40 years and is safe for most people with diabetes.-DrC #healthtalk \n",
      "\n",
      "RT @NPF: What works for one person with #psoriasis might not work for another. Keep trying until you find the right regimen for you #healthtalk \n",
      "\n",
      "----------------------------\n",
      "RT @lizlandau: US gets a D+ for failing to support emergency care patients, report says #health \n",
      "\n",
      "America's emergency care system gets a big 'ol D+ for 2013. Do you agree? \n",
      "\n",
      "RT @ASH_hematology: Clinton's #bloodclot \"relatively rare,\" Dr. Mary Cushman, Chair of ASH Subcmte on Quality of Care, tells @CNNHealth: ... \n",
      "\n",
      "One in five care homes 'fail key test' \n",
      "\n",
      "VIDEO: Care: 'You have to be cold-hearted' \n",
      "\n",
      "VIDEO: Fears for Scope care home residents \n",
      "\n",
      "----------------------------\n",
      "You may not be better off after knee surgery, study says \n",
      "\n",
      "One more reason to eat fatty fish! New study shows it may prevent #rheumatoid #arthritis \n",
      "\n",
      "Sitting less may prevent #diabetes risk factors, new study says. Are you able to move around at work? \n",
      "\n",
      "Obscure drug helps obese mice get thin without exercise. Could it work for humans? \n",
      "\n",
      "How you cope with #stress before it happens may affect recovery, study suggests \n",
      "\n",
      "Blood sugar is NOT what matters most for preventing heart disease in people with #diabetes, new study finds \n",
      "\n",
      "----------------------------\n",
      ".@HPutt @CDCgov warns against any nonessential travel to the region but has not banned outright. Quarantine period is 3 wks for #Ebola \n",
      "\n",
      ".@Insperity formed a GIANT human heart before kicking off their awareness walk for @American_Heart #heartmonth win! \n",
      "\n",
      "Parents honor son who died from rare heart disease with annual hockey tournament  \n",
      "\n",
      "Families speak out against doctor who said â€˜death from cancer is the bestâ€™ \n",
      "\n",
      "Moms should let their babies cry themselves back to sleep after waking up during the night, finds a new study: \n",
      "\n",
      "A young girl killed herself after #youtube pleas. Read the heartbreaking story: \n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for p in indexes_per_medoid:\n",
    "    info = np.take(news,p,0).loc[:,\"headline_test\"].values\n",
    "    print(\"----------------------------\")\n",
    "    for i in range(info.size):\n",
    "        print(info[i],\"\\n\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating cloud of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs('../output/w2vec_wordcloud_clusters/', exist_ok=True)\n",
    "os.makedirs('../output/w2vec_wordcloud_medoids/', exist_ok=True)\n",
    "\n",
    "# clusters\n",
    "for i in range(best_K):\n",
    "    info = ' '.join(news[y_pred==i].loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/w2vec_wordcloud_clusters/k_\"+str(i))\n",
    "    plt.close(fig)\n",
    "\n",
    "#medoids\n",
    "for i in range(selected_medoids_index.size):\n",
    "    p = indexes_per_medoid[i]\n",
    "    info = ' '.join(np.take(news,p,0).loc[:,\"headline_test\"])\n",
    "    wordcloud = WordCloud(random_state=42).generate(info)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")    \n",
    "    fig.savefig(\"../output/w2vec_wordcloud_medoids/k_\"+str(selected_medoids_index[i]))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
